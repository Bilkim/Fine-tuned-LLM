# -*- coding: utf-8 -*-
"""

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WnEdk98SIC9ch-n0dTpWg-tHxbCXnP-_

# Fine-tuning a language model
"""


from datasets import load_dataset
from transformers import AutoTokenizer, TrainingArguments, Trainer
from transformers import AutoModelForSequenceClassification
import numpy as np
from evaluate import load
import torch

# Yelp Review data
dataset = load_dataset("yelp_review_full")

# Tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")

# Tokenization function
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True, max_length=512)

# Tokenize the dataset
tokenized_datasets = dataset.map(tokenize_function, batched=True)

# Create small training and evaluation sets
small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))

# Load the pretrained BERT model
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    accuracy_metric = load("accuracy")
    return {"accuracy": accuracy_metric.compute(predictions=predictions, references=labels)["accuracy"]}


# Training arguments
training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch"
)

# Initializing the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=lambda p: {"accuracy": load("accuracy").compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)}
)

# Fine-tune the model
trainer.train()

# Evaluate the model after training
trainer.evaluate()

"""# Inferencing with the fine-tuned language model"""

reviews = [
    "Let this review be your reason to visit. We were celebrating my birthday this evening, and I was so happy to share my favorite meals that remind me of home with my American friends. Everyone at the table loved the food. Excellent and attentive service complemented incredible food. I am so grateful for every person who works at Nene’s.",
    "First time having Ukrainian food! It was delicious, but we waited about 1h20min for our entrees. I think that discourages me a bit to come back soon, despite the great food and atmosphere. I would still recommend this place.",
    "In the evening the establishment was full, but we were served quickly enough, the waiter was very nice and quite attentive). Of all the dishes I liked the kharcho soup, very tasty). Pancakes with cottage cheese are tasty, but a little undercooked). Khachapuri is not tasty at all, as if it came from frozen. The dough is hard, there is not enough cheese. Draniki are half raw. Pkhali are not similar to pkhali.",
    "Little bit disappointed. The food tastes good. Nice aromatic seasonings. Food processing time is heavily diversified Ajaruli Khachapuri was burned and cheese was hard. Might be it was warmed up second time in the oven. Pic is included. Khinkali was good.",
    "Today we were served rotten fish on potato pancakes. The fish smelled terrible. Never in 9 years in the United States have I been served rotten fish. We were with a small child, I can’t even imagine what would have happened to the child if he had eaten rotten fish. This would be our third time at the restaurant. Service is always great, food is mediocre. . . but, guys, rotten fish, seriously? I wanted to support this restaurant because the idea is amazing, but after today I can’t."
]

# The trained model is accessed from the trainer
model = trainer.model

# Tokenize the reviews
tokenized_reviews = tokenizer(reviews, padding=True, truncation=True, return_tensors="pt")

model = model.cuda()

tokenized_reviews = tokenized_reviews.to('cuda')

# Perform inference
model.eval() # Set the model to evaluation mode

with torch.no_grad():
    outputs = model(**tokenized_reviews)
    predictions = torch.argmax(outputs.logits, dim=1)

# Convert predictions to list for easy viewing
predicted_ratings = predictions.cpu().tolist()

# Print the predicted ratings
for review, rating in zip(reviews, predicted_ratings):
    print(f"Review: {review}\nPredicted Rating: {rating}\n")

"""# Fine-tuning a vision transformer"""

import torch
import numpy as np

from datasets import load_dataset
from transformers import AutoImageProcessor
from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor
from transformers import DefaultDataCollator, ViTForImageClassification, TrainingArguments, Trainer
from evaluate import load

# Loading the Food101 dataset
food = load_dataset("food101", split="train[:5000]")
food = food.train_test_split(test_size=0.2)

# Creating label dictionaries
labels = food["train"].features["label"].names
label2id, id2label = dict(), dict()

for i, label in enumerate(labels):
    label2id[label] = str(i)
    id2label[str(i)] = label

# Load the image processor for ViT
checkpoint = "google/vit-base-patch16-224-in21k"
image_processor = AutoImageProcessor.from_pretrained(checkpoint)

# Image transformation
normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
size = (
    image_processor.size["shortest_edge"]
    if "shortest_edge" in image_processor.size
    else (image_processor.size["height"], image_processor.size["width"])
)

_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])

# Preprocessing function
def transforms(examples):
    examples["pixel_values"] = [_transforms(img.convert("RGB")) for img in examples["image"]]
    del examples["image"]
    return examples

# Apply preprocessing
food = food.with_transform(transforms)

data_collator = DefaultDataCollator()

# Load the pretrained ViT model
model = ViTForImageClassification.from_pretrained(checkpoint, num_labels=len(labels), id2label=id2label, label2id=label2id)

# Training arguments
training_args = TrainingArguments(
    output_dir="./results_vit",
    learning_rate=5e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch"
)

# Initialize the Trainer with the preprocessed dataset
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=food["train"],
    eval_dataset=food["test"],
    data_collator=data_collator,
    compute_metrics=lambda p: {"accuracy": load("accuracy").compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)}
)

print(food["train"][0])  # Check the structure of a single example

# Fine-tune the model
trainer.train()

# Evaluate the model after training
trainer.evaluate()

"""#  Inference with the fine-tuned vision model"""

import matplotlib.pyplot as plt
from PIL import Image

# Load the validation dataset
ds = load_dataset("food101", split="validation[:1000]")

# Loading model
fine_tuned_model = trainer.model

# Selected indices for inference
indices = [0, 299, 599, 899]

# Preprocess and perform inference
for idx in indices:
    # Original image
    image = ds[idx]["image"]
    plt.imshow(image)
    plt.axis("off")
    plt.show()

    # Preprocess the image
    processed_image = _transforms(image.convert("RGB")).unsqueeze(0)  # Adding batch dimension

    # Model inference
    fine_tuned_model.eval()
    with torch.no_grad():
        outputs = fine_tuned_model(processed_image)
        prediction = torch.argmax(outputs.logits, dim=1)

    # Get the predicted class
    predicted_class = id2label[str(prediction.item())]
    print(f"Image Index: {idx}, Predicted Class: {predicted_class}")